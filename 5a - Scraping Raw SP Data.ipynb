{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseball Prediction: 5a - Getting (Raw) Individual Pitcher Data\n",
    "\n",
    "In the previous notebook, we compared our simple, hitting-only model to the Las Vegas odds. We concluded that incorporating the starting pitcher information would be a crucial next step to improve our model.\n",
    "\n",
    "In this notebook we will learn how to scrape individual, game-level, pitching data from retrosheet. We will write a loop to go through and download the data. This will enable us to augment our game-level dataframe with features derived from the previous performance of the starting pitcher.\n",
    "\n",
    "Let's start by going to retrosheet and finding the stats for Corey Kluber (one of my favorite pitchers from my childhood).\n",
    "\n",
    "www.retrosheet.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_rows',1000)\n",
    "\n",
    "import lxml\n",
    "import html5lib\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.retrosheet.org/boxesetc/2016/Kklubc0010062016.htm'\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = list(soup.children)[-1]\n",
    "soup1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = list(soup1.children)[-1]\n",
    "soup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup3 = list(soup2.children)\n",
    "soup3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_num = np.where([\"Opponent\" in str(x) for x in soup3])[0][0]\n",
    "index_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup4 = soup3[index_num]\n",
    "soup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup5 = list(soup4.children)\n",
    "soup5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    print(soup5[i].get_text().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Given the url that refers to a specific pitcher and season\n",
    "## we scrape the data and process it a bit\n",
    "def get_season_pitching_data(url):    \n",
    "    time.sleep(1)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    html=list(soup.children)[-1]\n",
    "    body = list(html.children)[-1]\n",
    "    sec_next = list(body.children)\n",
    "    secnum = np.where([\"Opponent\" in str(x) for x in sec_next])[0][0]\n",
    "    key_section = sec_next[secnum]\n",
    "    working_part = list(key_section.children)\n",
    "    p_header = working_part[0].strip().split()\n",
    "    mod_header= ['at_vs','Opponent','League', 'GS', 'CG', 'SHO', 'GF', 'SV', 'IP', 'H',\n",
    "            'BFP', 'HR', 'R', 'ER', 'BB', 'IB', 'SO', 'SH', 'SF', 'WP', 'HBP',\n",
    "            'BK', '2B', '3B', 'GDP', 'ROE', 'W', 'L', 'ERA']\n",
    "\n",
    "    date_list = []\n",
    "    day_href_list = []\n",
    "    for k in range(1,len(working_part),4):\n",
    "        date_list.append(working_part[k].get_text().strip())\n",
    "        day_href_list.append(working_part[k].attrs['href'])\n",
    "\n",
    "    dblhead_num_list = []\n",
    "    for k in range(2,len(working_part),4):\n",
    "        dblhead_num_list.append(working_part[k].strip())\n",
    "\n",
    "    game_href_list = []\n",
    "    for k in range(3,len(working_part),4):\n",
    "        game_href_list.append(working_part[k].attrs['href'])\n",
    "\n",
    "    main_data_matrix = []\n",
    "    for k in range(4,len(working_part),4):\n",
    "        main_data_row = (working_part[k].strip().split())[:29]\n",
    "        main_data_matrix.append(main_data_row)\n",
    "\n",
    "    out_df = pd.DataFrame(main_data_matrix, columns = mod_header)\n",
    "    out_df['Date'] = date_list\n",
    "    out_df['dblhead_num'] = dblhead_num_list\n",
    "    return(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_season_pitching_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.retrosheet.org/boxesetc/K/Pklubc001.htm'\n",
    "page = requests.get(url)\n",
    "sup = BeautifulSoup(page.content, 'html.parser')\n",
    "sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup2 = list(sup.children)[2]\n",
    "sup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup3 = list(sup2.children)[5]\n",
    "sup3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan - find the <pre> tag that starts with 'Pitching Record' (after stripping whitespace)\n",
    "# Get the href attribute for all the <a> tags with the word \"Daily\"\n",
    "\n",
    "pre_tags = [x for x in sup3.find_all('pre')]\n",
    "pre_tag_text = [x.get_text().strip() for x in pre_tags]\n",
    "pre_tag_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where([x.startswith('Pitching Record') for x in pre_tag_text])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where([x.startswith('Pitching Record') for x in pre_tag_text])[0][0]\n",
    "a_tags = pre_tags[ind].find_all('a')\n",
    "a_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [x.attrs['href'] for x in a_tags if x.get_text()=='Daily']\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the links to the pitcher-season tables given the pitcher id\n",
    "def get_daily_season_links(pitcher_id):\n",
    "    letter = pitcher_id.upper()[0]\n",
    "    url_prefix = 'https://www.retrosheet.org/boxesetc/'\n",
    "    url = url_prefix+letter+'/P'+pitcher_id+'.htm'\n",
    "    time.sleep(1)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    html=list(soup.children)\n",
    "    body = list(html[2].children)[5]\n",
    "    pre_texts = [x for x in body.find_all('pre')]\n",
    "    secnum = np.where([x.get_text().strip().startswith('Pitching Record') for x in pre_texts])[0][0]\n",
    "    a_pre_texts = pre_texts[secnum].find_all('a')\n",
    "    daily_season_links = [url_prefix+x.attrs['href'][3:] for x in a_pre_texts if x.get_text()=='Daily']\n",
    "    return(daily_season_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_daily_season_links('klubc001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_season_pitching_data(get_daily_season_links('klubc001')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the data for a particular pitcher\n",
    "def get_full_pitching_data(pitcher_id):\n",
    "    link_list = get_daily_season_links(pitcher_id)\n",
    "    df_pitching = pd.DataFrame()\n",
    "    for url in link_list:\n",
    "        df_pitching = pd.concat((df_pitching, get_season_pitching_data(url)))\n",
    "    return(df_pitching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_data = get_full_pitching_data('klubc001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_data.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD IN GAME LEVEL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_bp3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pitchers_h = df.pitcher_start_id_h.unique()\n",
    "start_pitchers_v = df.pitcher_start_id_v.unique()\n",
    "len(start_pitchers_h), len(start_pitchers_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6212,\n",
       " array(['aased001', 'abadf001', 'abboc001', 'abbog001', 'abboj001',\n",
       "        'abbok001', 'abbop001', 'abera101', 'abert101', 'abert102',\n",
       "        'aberw101', 'ableh101', 'abrej001', 'aceva001', 'acevj001',\n",
       "        'acevj002', 'ackej001', 'acket101', 'acklf101', 'acose101',\n",
       "        'acosj101', 'adama002', 'adama101', 'adamb102', 'adamb104'],\n",
       "       dtype='<U8'))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_pitchers_all = np.union1d(start_pitchers_h.astype(str), start_pitchers_v.astype(str))\n",
    "len(start_pitchers_all), start_pitchers_all[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bacsm001'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_pitchers_all[196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this for everyone in the list - may take a bit to run...\n",
    "\n",
    "for p_id in start_pitchers_all:\n",
    "    print(p_id)\n",
    "    try:\n",
    "        df_temp = get_full_pitching_data(p_id)\n",
    "    except (AttributeError, AssertionError, ValueError):\n",
    "        pass\n",
    "\n",
    "    fname_out = '/Users/antiprotons/Desktop/DA/SP_Data/pitching_data_'+p_id+'.csv'\n",
    "    df_temp.to_csv(fname_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
